{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Multi-Dataset Merger (v2) - Student Dropout Prediction\n",
                "## Combining 5 Datasets for Maximum Accuracy\n",
                "\n",
                "**Updates in v2:**\n",
                "- Fixed CSV loading for semicolon-separated files\n",
                "- Improved target variable detection (avoids 'Marital status' confusion)\n",
                "- Fixed pandas compatibility issues"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import sys\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Add parent directory to path\n",
                "sys.path.append('..')\n",
                "import config\n",
                "\n",
                "print(\"‚úì Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load All Datasets (Robust Loading)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load each dataset with smart separator detection\n",
                "datasets = {}\n",
                "\n",
                "dataset_info = [\n",
                "    ('dataset1', config.DATASET_1_PATH),\n",
                "    ('dataset2', config.DATASET_2_PATH),\n",
                "    ('dataset3', config.DATASET_3_PATH),\n",
                "    ('dataset4', config.DATASET_4_PATH),\n",
                "    ('dataset5', config.DATASET_5_PATH)\n",
                "]\n",
                "\n",
                "for name, path in dataset_info:\n",
                "    try:\n",
                "        # Try loading with default comma separator\n",
                "        df = pd.read_csv(path)\n",
                "        \n",
                "        # If only 1 column found, try semicolon separator\n",
                "        if df.shape[1] == 1:\n",
                "            df = pd.read_csv(path, sep=';')\n",
                "            \n",
                "        datasets[name] = df\n",
                "        print(f\"‚úì {config.DATASET_NAMES[name]:40} - {df.shape[0]:5,} rows √ó {df.shape[1]:2} columns\")\n",
                "    except FileNotFoundError:\n",
                "        print(f\"‚úó {config.DATASET_NAMES[name]:40} - FILE NOT FOUND\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚úó {config.DATASET_NAMES[name]:40} - ERROR: {str(e)}\")\n",
                "\n",
                "print(f\"\\nüìä Total datasets loaded: {len(datasets)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Standardize Target Variables (Fixed Logic)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fixed Function to standardize target variable\n",
                "def standardize_target(df, target_col=None):\n",
                "    \"\"\"\n",
                "    Standardize target variable to: Dropout, Graduate, Enrolled\n",
                "    \"\"\"\n",
                "    df_copy = df.copy()\n",
                "    \n",
                "    # 1. Auto-detect target column if not provided\n",
                "    if target_col is None:\n",
                "        # Priority 1: Exact match for 'Target'\n",
                "        if 'Target' in df_copy.columns:\n",
                "            target_col = 'Target'\n",
                "        # Priority 2: Exact match for 'target'\n",
                "        elif 'target' in df_copy.columns:\n",
                "            target_col = 'target'\n",
                "        # Priority 3: Search for keywords, excluding 'Marital status'\n",
                "        else:\n",
                "            target_candidates = ['Dropout', 'Status', 'dropout', 'status']\n",
                "            for candidate in target_candidates:\n",
                "                # Find columns containing the candidate string\n",
                "                matches = [col for col in df_copy.columns if candidate in col]\n",
                "                # Filter out 'Marital status' which is a feature, not target\n",
                "                matches = [m for m in matches if 'marital' not in m.lower()]\n",
                "                \n",
                "                if matches:\n",
                "                    target_col = matches[0]\n",
                "                    break\n",
                "    \n",
                "    if target_col is None:\n",
                "        print(f\"‚ö†Ô∏è No target column found. Skipping...\")\n",
                "        return df_copy\n",
                "    \n",
                "    print(f\"  Identified target column: '{target_col}'\")\n",
                "    \n",
                "    # 2. Rename to 'Target'\n",
                "    if target_col != 'Target':\n",
                "        # If 'Target' already exists (but isn't the one we picked), drop it to avoid duplicates\n",
                "        if 'Target' in df_copy.columns:\n",
                "            print(\"  Dropping existing 'Target' column to avoid duplicates\")\n",
                "            df_copy = df_copy.drop(columns=['Target'])\n",
                "        df_copy = df_copy.rename(columns={target_col: 'Target'})\n",
                "    \n",
                "    # 3. Standardize values (Robust method)\n",
                "    # Convert to string first, then strip\n",
                "    df_copy['Target'] = df_copy['Target'].astype(str)\n",
                "    df_copy['Target'] = df_copy['Target'].str.strip()\n",
                "    \n",
                "    return df_copy\n",
                "\n",
                "# Apply standardization\n",
                "standardized_datasets = {}\n",
                "for name, df in datasets.items():\n",
                "    print(f\"\\nProcessing {config.DATASET_NAMES[name]}...\")\n",
                "    standardized_datasets[name] = standardize_target(df)\n",
                "    if 'Target' in standardized_datasets[name].columns:\n",
                "        print(f\"‚úì Target standardized. Values: {standardized_datasets[name]['Target'].unique()[:5]}\")\n",
                "    else:\n",
                "        print(f\"‚úó No target found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Harmonization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define key features to extract/engineer\n",
                "KEY_FEATURES = [\n",
                "    'age',\n",
                "    'gender',\n",
                "    'course',\n",
                "    'year_of_study',\n",
                "    'previous_qualification',\n",
                "    'admission_grade',\n",
                "    'mother_qualification',\n",
                "    'father_qualification',\n",
                "    'tuition_fees_up_to_date',\n",
                "    'scholarship_holder',\n",
                "    'debtor',\n",
                "    'curricular_units_1st_sem',\n",
                "    'curricular_units_2nd_sem',\n",
                "    'unemployment_rate',\n",
                "    'inflation_rate',\n",
                "    'gdp'\n",
                "]\n",
                "\n",
                "def harmonize_features(df, dataset_name):\n",
                "    \"\"\"\n",
                "    Extract and harmonize features from dataset\n",
                "    \"\"\"\n",
                "    harmonized = pd.DataFrame()\n",
                "    \n",
                "    # Add dataset source\n",
                "    harmonized['dataset_source'] = dataset_name\n",
                "    \n",
                "    # Map columns to standard names\n",
                "    for col in df.columns:\n",
                "        col_lower = col.lower().replace(' ', '_')\n",
                "        \n",
                "        # Age\n",
                "        if 'age' in col_lower:\n",
                "            harmonized['age'] = df[col]\n",
                "        \n",
                "        # Gender\n",
                "        elif 'gender' in col_lower or 'sex' in col_lower:\n",
                "            harmonized['gender'] = df[col]\n",
                "        \n",
                "        # Course\n",
                "        elif 'course' in col_lower:\n",
                "            harmonized['course'] = df[col]\n",
                "        \n",
                "        # Add more mappings as needed\n",
                "    \n",
                "    # Add target if available\n",
                "    if 'Target' in df.columns:\n",
                "        harmonized['Target'] = df['Target']\n",
                "    \n",
                "    # Fill missing columns with NaN\n",
                "    for feature in KEY_FEATURES:\n",
                "        if feature not in harmonized.columns:\n",
                "            harmonized[feature] = np.nan\n",
                "    \n",
                "    return harmonized\n",
                "\n",
                "print(\"Harmonizing datasets...\\n\")\n",
                "harmonized_datasets = {}\n",
                "for name, df in standardized_datasets.items():\n",
                "    harmonized_datasets[name] = harmonize_features(df, config.DATASET_NAMES[name])\n",
                "    print(f\"‚úì {config.DATASET_NAMES[name]:40} - {harmonized_datasets[name].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Merge and Save"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Concatenate all harmonized datasets\n",
                "merged_df = pd.concat(harmonized_datasets.values(), ignore_index=True)\n",
                "\n",
                "# Basic cleaning\n",
                "if 'Target' in merged_df.columns:\n",
                "    merged_df = merged_df.dropna(subset=['Target'])\n",
                "\n",
                "# Save merged dataset\n",
                "output_path = config.MERGED_DATASET_PATH\n",
                "merged_df.to_csv(output_path, index=False)\n",
                "\n",
                "print(f\"\\n‚úì Merged dataset saved to: {output_path}\")\n",
                "print(f\"  Total records: {len(merged_df):,}\")\n",
                "print(f\"  Total features: {merged_df.shape[1]}\")\n",
                "\n",
                "display(merged_df.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}