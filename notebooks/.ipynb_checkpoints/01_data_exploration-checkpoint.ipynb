{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Student Dropout Prediction - Data Exploration\n",
                "## Notebook 1: Exploratory Data Analysis\n",
                "\n",
                "This notebook explores the Student Mental Health dataset to understand:\n",
                "- Dataset structure and characteristics\n",
                "- Distribution of features\n",
                "- Missing values and data quality\n",
                "- Relationships between features\n",
                "- Initial insights for dropout prediction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Add parent directory to path\n",
                "sys.path.append('..')\n",
                "\n",
                "from src.utils import (\n",
                "    load_data, get_missing_value_summary,\n",
                "    plot_feature_distributions, plot_correlation_matrix\n",
                ")\n",
                "import config\n",
                "\n",
                "# Configure plotting\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "%matplotlib inline\n",
                "\n",
                "# Display settings\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "\n",
                "# Random seed\n",
                "np.random.seed(config.RANDOM_STATE)\n",
                "\n",
                "print(\"‚úì Libraries imported successfully\")\n",
                "print(f\"Working Directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Dataset\n",
                "\n",
                "**Dataset**: Student Mental Health Dataset from Kaggle\n",
                "\n",
                "‚ö†Ô∏è **IMPORTANT**: Make sure you have downloaded the dataset and placed it in `data/raw/student_mental_health.csv`\n",
                "\n",
                "If you haven't downloaded it yet:\n",
                "1. Go to Kaggle: https://www.kaggle.com/datasets\n",
                "2. Search for \"Student Mental Health\"\n",
                "3. Download the CSV file\n",
                "4. Place it in `../data/raw/student_mental_health.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "try:\n",
                "    df = load_data(config.DATASET_PATH)\n",
                "    print(f\"\\n‚úì Dataset loaded successfully!\")\n",
                "    print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
                "except FileNotFoundError as e:\n",
                "    print(f\"\\n‚ùå Error: {e}\")\n",
                "    print(\"\\nPlease download the dataset and place it in the correct location.\")\n",
                "    print(\"Expected path:\", config.DATASET_PATH)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initial Data Inspection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display first few rows\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"FIRST 5 ROWS OF THE DATASET\")\n",
                "print(\"=\"*80 + \"\\n\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset info\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"DATASET INFORMATION\")\n",
                "print(\"=\"*80 + \"\\n\")\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical summary\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"STATISTICAL SUMMARY\")\n",
                "print(\"=\"*80 + \"\\n\")\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Column names and types\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"COLUMN INFORMATION\")\n",
                "print(\"=\"*80 + \"\\n\")\n",
                "\n",
                "column_info = pd.DataFrame({\n",
                "    'Column': df.columns,\n",
                "    'Type': df.dtypes.values,\n",
                "    'Non-Null Count': df.count().values,\n",
                "    'Null Count': df.isnull().sum().values,\n",
                "    'Unique Values': [df[col].nunique() for col in df.columns]\n",
                "})\n",
                "\n",
                "print(column_info.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Missing Value Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "missing_summary = get_missing_value_summary(df)\n",
                "\n",
                "if not missing_summary.empty:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"MISSING VALUES SUMMARY\")\n",
                "    print(\"=\"*80 + \"\\n\")\n",
                "    print(missing_summary.to_string(index=False))\n",
                "    \n",
                "    # Visualize missing values\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.barh(missing_summary['Column'], missing_summary['Missing_Percentage'], color='coral')\n",
                "    plt.xlabel('Missing Percentage (%)', fontsize=12)\n",
                "    plt.title('Missing Values by Column', fontsize=14, fontweight='bold')\n",
                "    plt.grid(axis='x', alpha=0.3)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"\\n‚úì No missing values found in the dataset!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Target Variable Analysis\n",
                "\n",
                "**Note**: The actual target variable name may differ. Update this section based on your dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify potential target variable\n",
                "# Common names: 'dropout', 'status', 'target', 'label', etc.\n",
                "print(\"\\nColumn names:\")\n",
                "print(df.columns.tolist())\n",
                "\n",
                "# TODO: Update 'target_column' with the actual dropout indicator column\n",
                "# target_column = 'dropout'  # Replace with actual column name\n",
                "# \n",
                "# if target_column in df.columns:\n",
                "#     print(f\"\\n\" + \"=\"*80)\n",
                "#     print(f\"TARGET VARIABLE: {target_column}\")\n",
                "#     print(\"=\"*80 + \"\\n\")\n",
                "#     \n",
                "#     # Value counts\n",
                "#     print(df[target_column].value_counts())\n",
                "#     print(f\"\\nDropout Rate: {df[target_column].mean():.2%}\")\n",
                "#     \n",
                "#     # Visualize class distribution\n",
                "#     fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "#     \n",
                "#     # Count plot\n",
                "#     df[target_column].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
                "#     axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
                "#     axes[0].set_xlabel('Class', fontsize=12)\n",
                "#     axes[0].set_ylabel('Count', fontsize=12)\n",
                "#     axes[0].grid(axis='y', alpha=0.3)\n",
                "#     \n",
                "#     # Pie chart\n",
                "#     df[target_column].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
                "#                                           colors=['#2ecc71', '#e74c3c'])\n",
                "#     axes[1].set_ylabel('')\n",
                "#     axes[1].set_title('Class Proportion', fontsize=14, fontweight='bold')\n",
                "#     \n",
                "#     plt.tight_layout()\n",
                "#     plt.show()\n",
                "# else:\n",
                "#     print(f\"\\n‚ö†Ô∏è Target column '{target_column}' not found!\")\n",
                "#     print(\"Please update the target_column variable with the correct column name.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Feature Distribution Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate numerical and categorical features\n",
                "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
                "categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
                "\n",
                "print(f\"\\nNumerical Features ({len(numerical_features)}):\")\n",
                "print(numerical_features)\n",
                "\n",
                "print(f\"\\nCategorical Features ({len(categorical_features)}):\")\n",
                "print(categorical_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot numerical feature distributions\n",
                "if numerical_features:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"NUMERICAL FEATURE DISTRIBUTIONS\")\n",
                "    print(\"=\"*80 + \"\\n\")\n",
                "    \n",
                "    plot_feature_distributions(df, numerical_features[:9], ncols=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot categorical feature distributions\n",
                "if categorical_features:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"CATEGORICAL FEATURE DISTRIBUTIONS\")\n",
                "    print(\"=\"*80 + \"\\n\")\n",
                "    \n",
                "    plot_feature_distributions(df, categorical_features[:9], ncols=3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Correlation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation matrix for numerical features\n",
                "if len(numerical_features) > 1:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"CORRELATION ANALYSIS\")\n",
                "    print(\"=\"*80 + \"\\n\")\n",
                "    \n",
                "    plot_correlation_matrix(df[numerical_features])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Outlier Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Box plots for numerical features to detect outliers\n",
                "if numerical_features:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"OUTLIER DETECTION (Box Plots)\")\n",
                "    print(\"=\"*80 + \"\\n\")\n",
                "    \n",
                "    n_features = min(len(numerical_features), 9)\n",
                "    fig, axes = plt.subplots((n_features + 2) // 3, 3, figsize=(15, 3 * ((n_features + 2) // 3)))\n",
                "    axes = axes.flatten() if n_features > 1 else [axes]\n",
                "    \n",
                "    for idx, feature in enumerate(numerical_features[:n_features]):\n",
                "        df.boxplot(column=feature, ax=axes[idx])\n",
                "        axes[idx].set_title(f'{feature}', fontweight='bold')\n",
                "        axes[idx].grid(alpha=0.3)\n",
                "    \n",
                "    # Hide unused subplots\n",
                "    for idx in range(n_features, len(axes)):\n",
                "        axes[idx].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Key Insights and Next Steps\n",
                "\n",
                "### Observations:\n",
                "1. **Dataset Size**: [Update after running]\n",
                "2. **Missing Values**: [Update after running]\n",
                "3. **Class Balance**: [Update after running]\n",
                "4. **Feature Types**: [Update after running]\n",
                "5. **Outliers**: [Update after running]\n",
                "\n",
                "### Next Steps:\n",
                "1. ‚úÖ Data exploration completed\n",
                "2. üìù Proceed to `02_data_preprocessing.ipynb` for:\n",
                "   - Handling missing values\n",
                "   - Feature engineering\n",
                "   - Encoding categorical variables\n",
                "   - Scaling numerical features\n",
                "   - Train-test split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save exploration summary\n",
                "summary = {\n",
                "    'total_rows': len(df),\n",
                "    'total_columns': len(df.columns),\n",
                "    'numerical_features': len(numerical_features),\n",
                "    'categorical_features': len(categorical_features),\n",
                "    'missing_values': df.isnull().sum().sum(),\n",
                "    'duplicate_rows': df.duplicated().sum()\n",
                "}\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"EXPLORATION SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "for key, value in summary.items():\n",
                "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
                "print(\"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}