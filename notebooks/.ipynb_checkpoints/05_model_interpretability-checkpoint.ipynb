{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîç Model Interpretability\n",
                "## Student Dropout Prediction Project\n",
                "\n",
                "**Goal:** Understand *why* the model makes specific predictions using SHAP (SHapley Additive exPlanations). This is crucial for identifying key drivers of student dropout."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import shap\n",
                "import joblib\n",
                "import sys\n",
                "import os\n",
                "import importlib\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Add parent directory to path\n",
                "sys.path.append('..')\n",
                "import config\n",
                "importlib.reload(config)\n",
                "\n",
                "print(\"‚úì Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data and Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    # Load Data\n",
                "    train_df = pd.read_csv(config.TRAIN_DATA_PATH)\n",
                "    test_df = pd.read_csv(config.TEST_DATA_PATH)\n",
                "    \n",
                "    X_train = train_df.drop(columns=['Target'])\n",
                "    y_train = train_df['Target']\n",
                "    X_test = test_df.drop(columns=['Target'])\n",
                "    y_test = test_df['Target']\n",
                "    \n",
                "    # Load Model\n",
                "    model_path = config.MODEL_DIR / \"best_model.pkl\"\n",
                "    model = joblib.load(model_path)\n",
                "    \n",
                "    print(f\"‚úì Data and Model loaded successfully\")\n",
                "    print(f\"Model type: {type(model).__name__}\")\n",
                "    \n",
                "except FileNotFoundError as e:\n",
                "    print(f\"‚ùå Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize SHAP Explainer\n",
                "We use `TreeExplainer` because our best model (Random Forest or XGBoost) is tree-based. This is faster and more exact than KernelExplainer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create object that can calculate shap values\n",
                "explainer = shap.TreeExplainer(model)\n",
                "\n",
                "# Calculate shap values. This is what we will plot.\n",
                "# We'll use a sample of the test set to speed up calculation if needed, \n",
                "# but for this dataset size, full test set might be okay.\n",
                "# Let's use a sample of 500 for speed in demonstration.\n",
                "X_test_sample = X_test.sample(n=500, random_state=config.RANDOM_STATE)\n",
                "shap_values = explainer.shap_values(X_test_sample)\n",
                "\n",
                "print(\"‚úì SHAP values calculated\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Global Feature Importance (Summary Plot)\n",
                "This plot shows the most important features for the model. \n",
                "- **Y-axis:** Features ordered by importance.\n",
                "- **X-axis:** SHAP value (impact on model output).\n",
                "- **Color:** Feature value (Red = High, Blue = Low)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary Plot for Class 0 (Dropout)\n",
                "# Note: For multi-class, shap_values is a list of arrays, one for each class.\n",
                "# We need to check the class mapping.\n",
                "\n",
                "class_names = ['Dropout', 'Enrolled', 'Graduate'] # Assuming standard encoding 0, 1, 2\n",
                "\n",
                "print(f\"Plotting SHAP summary for: {class_names[0]} (Target=0)\")\n",
                "plt.figure(figsize=(10, 8))\n",
                "shap.summary_plot(shap_values[0], X_test_sample, plot_type=\"dot\", show=False)\n",
                "plt.title(f\"SHAP Summary Plot - {class_names[0]}\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary Plot for Class 2 (Graduate)\n",
                "print(f\"Plotting SHAP summary for: {class_names[2]} (Target=2)\")\n",
                "plt.figure(figsize=(10, 8))\n",
                "shap.summary_plot(shap_values[2], X_test_sample, plot_type=\"dot\", show=False)\n",
                "plt.title(f\"SHAP Summary Plot - {class_names[2]}\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Dependence Plot\n",
                "Shows how a single feature affects the prediction, and how it interacts with another feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find the top feature automatically\n",
                "# Calculate mean absolute SHAP value for each feature for Class 0\n",
                "mean_shap = np.abs(shap_values[0]).mean(axis=0)\n",
                "top_feature_idx = np.argsort(mean_shap)[-1]\n",
                "top_feature_name = X_test.columns[top_feature_idx]\n",
                "\n",
                "print(f\"Top feature for Dropout prediction: {top_feature_name}\")\n",
                "\n",
                "# Dependence plot for the top feature\n",
                "shap.dependence_plot(top_feature_name, shap_values[0], X_test_sample, interaction_index='auto')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Local Explanation (Force Plot)\n",
                "Explain a *single* prediction. Why did the model predict Dropout/Graduate for this specific student?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select a specific student (e.g., the first one in our sample)\n",
                "student_idx = 0\n",
                "student_data = X_test_sample.iloc[student_idx]\n",
                "\n",
                "# Initialize JS for force plot visualization in notebook\n",
                "shap.initjs()\n",
                "\n",
                "print(f\"Explaining prediction for student #{student_idx}\")\n",
                "print(f\"Feature values:\\n{student_data}\")\n",
                "\n",
                "# Force plot for Class 0 (Dropout)\n",
                "shap.force_plot(explainer.expected_value[0], shap_values[0][student_idx], student_data, matplotlib=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Bar Plot of Feature Importance\n",
                "A simpler view of global importance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "shap.summary_plot(shap_values[0], X_test_sample, plot_type=\"bar\", show=False)\n",
                "plt.title(\"Feature Importance (SHAP) - Dropout Class\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}