\documentclass{SKP-beamer}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{pgfplots}
\usepackage{booktabs} % For better tables
\usepackage{graphicx} % For images
\usepackage{hyperref} % For clickable links

% --------------------------------------------------- %
%                  Presentation info                 %
% --------------------------------------------------- %
\title[Student Dropout Prediction]{Engagement \& Dropout Risk Prediction}
\subtitle{Using Machine Learning and Explainable AI}
\author[Santosh, Srujal, Khushboo]{Santosh Kumar Behera (22BTCSE68) \\ 
Srujal Prusty (22BTCSE80) \\ 
Khushboo Singh (22BTCSE93) \\ 
                    \vspace{0.5cm}
                    \small{Under the Supervision of} \\ 
                    Munmun Saha}
\institute[SUIIT]{ \small{Designation: Assistant Professor \\ 
                  Department of Computer Science and Engineering \\ 
                  Sambalpur University Institute of Information Technology \\ 
                  Jyoti Vihar, Burla-768019, Odisha, India }}
\date{\today}
\logo{\includegraphics[scale=0.6]{suiit.jpg}} % Ensure you have this image or comment it out
\subject{Student Dropout Prediction}

\begin{document}

% ---------------- Title --------------------
\begin{frame}
  \titlepage
\end{frame}

% ---------------- Outline --------------------
\begin{frame}{Presentation Outline}
\tableofcontents
\end{frame}

% ===================================================== %
% 1. INTRODUCTION
% ===================================================== %
\section{Introduction}

\begin{frame}{Introduction}
Student dropout is a significant challenge in higher education, resulting in substantial economic losses and untapped human potential. Early identification of at-risk students is crucial for implementing timely interventions and improving retention rates.
\vspace{0.3cm}

This project addresses this critical need by developing a comprehensive Machine Learning system capable of predicting student dropout risk with high accuracy.
\vspace{0.3cm}

Our solution integrates diverse data sources including academic performance and mental health indicators, utilizing advanced algorithms such as Random Forest and XGBoost. The system incorporates explainable AI techniques (SHAP) to provide transparent insights into prediction factors, and features a user-friendly Streamlit web application for real-time risk assessment and decision support.
\end{frame}

% ===================================================== %
% 2. RELATED WORK
% ===================================================== %
\section{Related Work}

\begin{frame}{Related Work}
\begin{table}[h]
\centering
\small
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Author(s)} & \textbf{Dataset} & \textbf{Model(s)} & \textbf{Key Findings} \\ \midrule
Sulak et al. (2024) & Single academic & RF, SVM, KNN & $\sim$95\% accuracy \\
 & dataset &  & on single dataset \\ \midrule
Vaarma (2024) & University & NN, DT & Early detection \\
 & records &  & focus \\ \midrule
Carnevale \& & K-12 student & Statistical & Identified economic \\
Desrochers & performance & analysis & roots of dropout \\ \bottomrule
\end{tabular}
\caption{Summary of Related Studies}
\end{table}

\vspace{0.3cm}

\textbf{Research Gaps \& Our Contribution:} Most existing studies rely on single, homogeneous datasets and lack mental health integration. They also present "black box" models without explainability. Our work addresses these gaps by merging \textbf{5 diverse datasets}, incorporating mental health factors, and implementing \textbf{SHAP} for transparent, actionable insights—creating a more robust and generalizable prediction system.
\end{frame}

% ===================================================== %
% 3. MODEL AND PROBLEM STATEMENT
% ===================================================== %
\section{Model and Problem Statement}

\begin{frame}{Problem Statement}
\begin{block}{Research Question}
How can we accurately predict student dropout risk using multi-source data and provide interpretable insights for timely intervention?
\end{block}

\vspace{0.3cm}

\textbf{Challenges:}
\begin{itemize}
    \item Data heterogeneity across multiple sources
    \item Class imbalance (fewer dropouts than graduates)
    \item Need for model interpretability for stakeholder trust
    \item Real-time prediction requirements
\end{itemize}

\vspace{0.3cm}

\textbf{Objectives:}
\begin{itemize}
    \item Achieve high prediction accuracy on diverse datasets
    \item Provide explainable predictions using SHAP
    \item Deploy a user-friendly web application
\end{itemize}
\end{frame}

\begin{frame}{Proposed Model Overview}
\centering
% IMAGE 1: System Architecture Diagram (Generated by AI)
\includegraphics[width=0.95\textwidth]{images/system_architecture.png}
\vspace{0.2cm}
\\
\tiny{Figure 1: End-to-End System Architecture - Data Collection to Deployment}
\end{frame}

% ===================================================== %
% 4. PROPOSED ALGORITHM / METHOD / SYSTEM
% ===================================================== %
\section{Proposed Algorithm / Method / System}

\begin{frame}{Data Integration Pipeline}
\textbf{Step 1: Multi-Dataset Integration}
\begin{itemize}
    \item Merged 5 diverse datasets:
    \begin{enumerate}
        \item Higher Education Predictors
        \item Student Performance (Math/Portuguese)
        \item Academic Success Records
        \item Mental Health Survey Data
        \item Dropout \& Success Indicators
    \end{enumerate}
    \item Total records: 9,013 students (after deduplication)
    \item Features: 15 key predictors (Academic, Financial, Economic)
\end{itemize}
\end{frame}

\begin{frame}{Preprocessing Pipeline}
\textbf{Step 2: Data Preprocessing}

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Missing Value Handling:}
\begin{itemize}
    \item Median imputation for numerical features
    \item Most frequent for categorical
\end{itemize}

\vspace{0.3cm}

\textbf{Feature Engineering:}
\begin{itemize}
    \item Binary encoding (0/1) for categorical
    \item Standardization (zero mean, unit variance)
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Class Balancing:}
\begin{itemize}
    \item \textbf{SMOTE} (Synthetic Minority Over-sampling)
    \item Balanced distribution:
    \begin{itemize}
        \item Dropout: 33\%
        \item Enrolled: 33\%
        \item Graduate: 34\%
    \end{itemize}
\end{itemize}
\end{column}
\end{columns}

\vspace{0.3cm}
\centering
\textbf{Train-Test Split:} 80\% Training | 20\% Testing
\end{frame}

\begin{frame}{Model Training Strategy}
\textbf{Step 3: Multi-Model Training \& Selection}

\begin{itemize}
    \item \textbf{Models Evaluated:}
    \begin{enumerate}
        \item Logistic Regression (Baseline)
        \item Support Vector Machine (SVM)
        \item \textbf{Random Forest} $\leftarrow$ Best Performer
        \item XGBoost
        \item Decision Tree
    \end{enumerate}
    
    \vspace{0.3cm}
    
    \item \textbf{Hyperparameter Tuning:}
    \begin{itemize}
        \item RandomizedSearchCV with 5-fold cross-validation
        \item Optimized for accuracy and F1-score
    \end{itemize}
    
    \vspace{0.3cm}
    
    \item \textbf{Best Model Configuration (Random Forest):}
    \begin{itemize}
        \item n\_estimators: 200
        \item max\_depth: 15
        \item min\_samples\_split: 5
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Explainability Module - SHAP}
\textbf{Step 4: Model Interpretation}

\begin{block}{SHAP (SHapley Additive exPlanations)}
Game-theoretic approach to explain individual predictions and global feature importance
\end{block}

\vspace{0.3cm}

\textbf{Two-Level Explanations:}
\begin{enumerate}
    \item \textbf{Global Interpretation:}
    \begin{itemize}
        \item Which features are most important overall?
        \item Ranking of predictors across all students
    \end{itemize}
    
    \vspace{0.2cm}
    
    \item \textbf{Local Interpretation:}
    \begin{itemize}
        \item Why did the model predict dropout for \textit{this} student?
        \item Feature contribution breakdown per prediction
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{Deployment - Streamlit Web Application}
\textbf{Step 5: Real-Time Prediction System}

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Features:}
\begin{itemize}
    \item Interactive input form
    \item Real-time predictions
    \item Confidence scores
    \item Visual probability bars
    \item Traffic light risk indicator:
    \begin{itemize}
        \item \textcolor{red}{Red}: Dropout
        \item \textcolor{orange}{Yellow}: Enrolled
        \item \textcolor{green}{Green}: Graduate
    \end{itemize}
\end{itemize}
\end{column}

\begin{column}{0.5\textwidth}
\centering
% IMAGE 6: Streamlit App Screenshot
\includegraphics[width=\textwidth]{images/streamlit_app.png}
\\
\tiny{Figure 2: Web Application Interface}
\end{column}
\end{columns}
\end{frame}

% ===================================================== %
% 5. PERFORMANCE METRICS & SIMULATION RESULTS
% ===================================================== %
\section{Performance Metrics \& Simulation Results}

\begin{frame}{Evaluation Metrics}
\begin{table}[]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Metric} & \textbf{Description} \\ \midrule
Accuracy & Overall correct predictions \\
Precision & True positives / (True + False positives) \\
Recall & True positives / (True + False negatives) \\
F1-Score & Harmonic mean of Precision \& Recall \\
Confusion Matrix & Class-wise prediction breakdown \\ \bottomrule
\end{tabular}
\caption{Performance Evaluation Metrics}
\end{table}
\end{frame}

\begin{frame}{Model Performance Comparison}
\begin{table}[]
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{F1-Score} \\ \midrule
Logistic Regression & 72\% & 0.70 \\
SVM & 74\% & 0.72 \\
\textbf{Random Forest} & \textbf{77\%} & \textbf{0.76} \\
XGBoost & 76\% & 0.75 \\
Decision Tree & 70\% & 0.68 \\ \bottomrule
\end{tabular}
\caption{Cross-Validation Performance (5-Fold)}
\end{table}

\vspace{0.3cm}

\centering
% IMAGE 3: Model Comparison Chart
\includegraphics[width=0.6\textwidth]{images/model_comparison.png}
\\
\tiny{Figure 3: Model Accuracy Comparison | Source: 03\_model\_training.ipynb}
\end{frame}

\begin{frame}{Confusion Matrix - Best Model}
\centering
% IMAGE 2: Confusion Matrix
\includegraphics[width=0.65\textwidth]{images/confusion_matrix_rf.png}
\\
\tiny{Figure 4: Random Forest Confusion Matrix | Source: 04\_model\_optimization.ipynb}

\vspace{0.3cm}

\textbf{Key Observations:}
\begin{itemize}
    \item High precision for Graduate class (lowest false positives)
    \item Balanced performance across all three classes
    \item Minimal confusion between Dropout and Graduate
\end{itemize}
\end{frame}

\begin{frame}{SHAP Analysis - Global Feature Importance}
\begin{columns}
\begin{column}{0.45\textwidth}
\textbf{Top 5 Predictors:}
\begin{enumerate}
    \item \textbf{Tuition Fees Status} \\
    \small{Financial commitment indicator}
    
    \item \textbf{Admission Grade} \\
    \small{Initial academic capability}
    
    \item \textbf{Age at Enrollment} \\
    \small{Maturity factor}
    
    \item \textbf{Scholarship Holder} \\
    \small{Financial support}
    
    \item \textbf{Unemployment Rate} \\
    \small{Economic context}
\end{enumerate}
\end{column}

\begin{column}{0.55\textwidth}
\centering
% IMAGE 4: SHAP Summary Plot
\includegraphics[width=\textwidth]{images/shap_summary.png}
\\
\tiny{Figure 5: SHAP Feature Importance}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{SHAP Analysis - Local Explanation}
\centering
% IMAGE 5: SHAP Force Plot
\includegraphics[width=0.9\textwidth]{images/shap_force_plot.png}
\\
\tiny{Figure 6: Individual Student Prediction Breakdown | Source: 05\_model\_interpretability.ipynb}

\vspace{0.4cm}

\textbf{Interpretation:}
\begin{itemize}
    \item Red bars $\rightarrow$ Push prediction toward Dropout
    \item Blue bars $\rightarrow$ Push prediction toward Graduate
    \item Enables personalized intervention strategies
\end{itemize}
\end{frame}

% ===================================================== %
% 6. ADVANTAGES
% ===================================================== %
\section{Advantages}

\begin{frame}{Why Our Approach is Better}
\begin{block}{Superior to Existing Methods}
\end{block}

\begin{enumerate}
    \item \textbf{Robustness Through Diversity}
    \begin{itemize}
        \item \textcolor{blue}{Ours:} 5 merged datasets (9,013 students) $\rightarrow$ Better generalization
        \item \textcolor{red}{Others:} Single dataset $\rightarrow$ Overfitting risk
    \end{itemize}
    
    \vspace{0.2cm}
    
    \item \textbf{Holistic Feature Set}
    \begin{itemize}
        \item \textcolor{blue}{Ours:} Academic + Mental Health + Economic indicators
        \item \textcolor{red}{Others:} Only academic performance
    \end{itemize}
    
    \vspace{0.2cm}
    
    \item \textbf{Explainability \& Trust}
    \begin{itemize}
        \item \textcolor{blue}{Ours:} SHAP explanations for every prediction $\rightarrow$ Stakeholder trust
        \item \textcolor{red}{Others:} Black-box models $\rightarrow$ No transparency
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{Advantages (Continued)}
\begin{enumerate}
\setcounter{enumi}{3}
    \item \textbf{Real-World Applicability}
    \begin{itemize}
        \item \textcolor{blue}{Ours:} 77\% accuracy on diverse data = Works across institutions
        \item \textcolor{red}{Others:} 90\%+ on single institution = Limited transferability
    \end{itemize}
    
    \vspace{0.2cm}
    
    \item \textbf{Actionable Insights}
    \begin{itemize}
        \item Identifies \textit{specific} risk factors per student
        \item Enables targeted counseling and financial aid decisions
        \item Reduces manual intervention efforts
    \end{itemize}
    
    \vspace{0.2cm}
    
    \item \textbf{User-Friendly Deployment}
    \begin{itemize}
        \item Streamlit web app $\rightarrow$ No technical expertise needed
        \item Real-time predictions $\rightarrow$ Instant decision support
        \item Scalable to thousands of students
    \end{itemize}
\end{enumerate}
\end{frame}

% ===================================================== %
% 7. TAKEAWAYS
% ===================================================== %
\section{Takeaways}

\begin{frame}{Key Takeaways}
\begin{block}{Main Contributions}
\end{block}

\begin{enumerate}
    \item \textbf{Multi-Dataset Integration is Crucial}
    \begin{itemize}
        \item Merging diverse sources creates robust, generalizable models
        \item Mental health + academic data = More comprehensive risk assessment
    \end{itemize}
    
    \vspace{0.3cm}
    
    \item \textbf{Explainability Matters}
    \begin{itemize}
        \item SHAP transforms ML from "black box" to "decision support tool"
        \item Educators can act on \textit{why}, not just \textit{what}
    \end{itemize}
    
    \vspace{0.3cm}
    
    \item \textbf{Real-World vs. Benchmark Accuracy}
    \begin{itemize}
        \item Our 77\% on 5 datasets > Their 95\% on 1 dataset (for deployment)
        \item Generalization > Overfitting to single institution
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{Practical Impact}
\begin{block}{Who Benefits?}
\end{block}

\begin{itemize}
    \item \textbf{Students:}
    \begin{itemize}
        \item Early identification $\rightarrow$ Timely support $\rightarrow$ Improved success rates
    \end{itemize}
    
    \vspace{0.2cm}
    
    \item \textbf{Educators \& Counselors:}
    \begin{itemize}
        \item Data-driven intervention strategies
        \item Prioritize high-risk students efficiently
    \end{itemize}
    
    \vspace{0.2cm}
    
    \item \textbf{Institutions:}
    \begin{itemize}
        \item Reduce dropout rates $\rightarrow$ Better retention metrics
        \item Optimize scholarship/financial aid allocation
    \end{itemize}
\end{itemize}

\vspace{0.3cm}

\centering
\textbf{Bottom Line:} This system bridges the gap between AI research and educational practice.
\end{frame}

% ===================================================== %
% 8. REFERENCES
% ===================================================== %
\section{References}

\begin{frame}{References}
\begin{enumerate}
    \item Suleyman Alpaslan Sulak, Nigmet Koklu. (2024). Predicting Student Dropout Using Machine Learning Algorithms. \textit{Intelligent Methods in Engineering Sciences}.
    
    \item Carnevale, A. P., \& Desrochers, D. M. (2003). Standards for what? The economic roots of K-12 education standards. \textit{Educational Policy}.
    
    \item Vaarma, M. (2024). Predicting student dropouts with machine learning. \textit{Computers \& Education}.
\end{enumerate}
\end{frame}

% ---------------- Thank You ---------------------
\section*{}
\begin{frame}
\centering
\Huge Thank You \\
\vspace{1cm}
\normalsize
Questions?
\end{frame}

\end{document}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{pgfplots}
\usepackage{booktabs} % For better tables
\usepackage{graphicx} % For images
\usepackage{hyperref} % For clickable links

% --------------------------------------------------- %
%                  Presentation info                 %
% --------------------------------------------------- %
\title[Student Dropout Prediction]{Engagement \& Dropout Risk Prediction}
\subtitle{Using Machine Learning and Explainable AI}
\author[Santosh, Srujal, Khushboo]{Santosh Kumar Behera (22BTCSE68) \\ 
Srujal Prusty (22BTCSE80) \\ 
Khushboo Singh (22BTCSE93) \\ 
                    \vspace{0.5cm}
                    \small{Under the Supervision of} \\ 
                    Munmun Saha}
\institute[SUIIT]{ \small{Designation: Assistant Professor \\ 
                  Department of Computer Science and Engineering \\ 
                  Sambalpur University Institute of Information Technology \\ 
                  Jyoti Vihar, Burla-768019, Odisha, India }}
\date{\today}
\logo{\includegraphics[scale=0.6]{suiit.jpg}} % Ensure you have this image or comment it out
\subject{Student Dropout Prediction}

\begin{document}

% ---------------- Title --------------------
\begin{frame}
  \titlepage
\end{frame}

% ---------------- Outline --------------------
\begin{frame}{Presentation Outline}
\tableofcontents
\end{frame}

% ===================================================== %
% 1. INTRODUCTION
% ===================================================== %
\section{Introduction}

\begin{frame}{Introduction}
Student dropout is a significant challenge in higher education, resulting in substantial economic losses and untapped human potential. Early identification of at-risk students is crucial for implementing timely interventions and improving retention rates.
\vspace{0.3cm}

This project addresses this critical need by developing a comprehensive Machine Learning system capable of predicting student dropout risk with high accuracy.
\vspace{0.3cm}

Our solution integrates diverse data sources including academic performance and mental health indicators, utilizing advanced algorithms such as Random Forest and XGBoost. The system incorporates explainable AI techniques (SHAP) to provide transparent insights into prediction factors, and features a user-friendly Streamlit web application for real-time risk assessment and decision support.
\end{frame}

% ===================================================== %
% 2. RELATED WORK
% ===================================================== %
\section{Related Work}

\begin{frame}{Related Work}
\begin{table}[h]
\centering
\small
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Author(s)} & \textbf{Dataset} & \textbf{Model(s)} & \textbf{Key Findings} \\ \midrule
Sulak et al. (2024) & Single academic & RF, SVM, KNN & $\sim$95\% accuracy \\
 & dataset &  & on single dataset \\ \midrule
Vaarma (2024) & University & NN, DT & Early detection \\
 & records &  & focus \\ \midrule
Carnevale \& & K-12 student & Statistical & Identified economic \\
Desrochers & performance & analysis & roots of dropout \\ \bottomrule
\end{tabular}
\caption{Summary of Related Studies}
\end{table}

\vspace{0.3cm}

\textbf{Research Gaps \& Our Contribution:} Most existing studies rely on single, homogeneous datasets and lack mental health integration. They also present "black box" models without explainability. Our work addresses these gaps by merging \textbf{5 diverse datasets}, incorporating mental health factors, and implementing \textbf{SHAP} for transparent, actionable insights—creating a more robust and generalizable prediction system.
\end{frame}

% ===================================================== %
% 3. METHODOLOGY
% ===================================================== %
\section{Methodology}

\begin{frame}{System Architecture}
\centering
% IMAGE 1: System Architecture Diagram (Generated by AI)
% Source: C:/Users/SAMEER/.gemini/antigravity/brain/.../system_architecture_diagram_*.png
\includegraphics[width=0.95\textwidth]{images/system_architecture.png}
\vspace{0.2cm}
\\
\tiny{Figure 1: End-to-End System Architecture - Data Collection to Deployment}
\end{frame}

\begin{frame}{Data Pipeline Overview}
\begin{enumerate}
    \item \textbf{Data Collection:} Merged 5 datasets (Student Performance, Mental Health, Academic Success, etc.).
    \vspace{0.2cm}
    \item \textbf{Preprocessing:}
    \begin{itemize}
        \item Handling Missing Values (Median Imputation)
        \item Encoding Categorical Variables
        \item \textbf{SMOTE:} Balancing "Dropout" vs "Graduate" classes
    \end{itemize}
    \vspace{0.2cm}
    \item \textbf{Model Training:} Logistic Regression, Random Forest, XGBoost, SVM
    \vspace{0.2cm}
    \item \textbf{Evaluation:} Accuracy, Precision, Recall, F1-Score
    \vspace{0.2cm}
    \item \textbf{Deployment:} Streamlit Web Application
\end{enumerate}
\end{frame}

\begin{frame}{Key Algorithms Used}
\begin{itemize}
    \item \textbf{Random Forest Classifier:}
    \begin{itemize}
        \item Ensemble learning method using multiple decision trees
        \item Robust against overfitting and handles non-linear data well
    \end{itemize}
    
    \item \textbf{XGBoost (Extreme Gradient Boosting):}
    \begin{itemize}
        \item High-performance gradient boosted decision trees
        \item Optimized for speed and performance
    \end{itemize}
    
    \item \textbf{SHAP (SHapley Additive exPlanations):}
    \begin{itemize}
        \item Game-theoretic approach to explain ML model outputs
        \item Provides global and local explanations
    \end{itemize}
\end{itemize}
\end{frame}

% ===================================================== %
% 4. RESULTS & DISCUSSION
% ===================================================== %
\section{Results and Discussion}

\begin{frame}{Model Performance Comparison}
\begin{table}[]
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{Key Observation} \\ \midrule
Logistic Regression & $\sim$72\% & Good baseline \\
SVM & $\sim$74\% & Computationally expensive \\
\textbf{Random Forest} & \textbf{$\sim$77\%} & \textbf{Best balance} \\
XGBoost & $\sim$76\% & Competitive \\ \bottomrule
\end{tabular}
\caption{Performance Comparison on Merged Dataset}
\end{table}

\vspace{0.2cm}

\centering
% IMAGE 2: Confusion Matrix for Best Model
% Source: Output from 03_model_training.ipynb or 04_model_optimization.ipynb
% Location: Generated when running the notebook, save as images/confusion_matrix_rf.png
\includegraphics[width=0.5\textwidth]{images/confusion_matrix_rf.png}
\\
\tiny{Figure 2: Confusion Matrix - Random Forest (Best Model) \\ Source: 04\_model\_optimization.ipynb}
\end{frame}

\begin{frame}{Model Performance - Real World Generalization}
\textit{Note: While single-dataset papers report 90\%+, our 77\% on a diverse, multi-source dataset indicates superior real-world generalization.}

\vspace{0.5cm}

\centering
% IMAGE 3: Model Comparison Bar Chart
% Source: From 03_model_training.ipynb - Model comparison visualization
% Save as images/model_comparison.png
\includegraphics[width=0.75\textwidth]{images/model_comparison.png}
\\
\tiny{Figure 3: Cross-Validation Accuracy Comparison \\ Source: 03\_model\_training.ipynb}
\end{frame}

\begin{frame}{Explainability - SHAP Analysis (Global)}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Top Predictors:}
\begin{enumerate}
    \item Tuition Fees Status
    \item 2nd Semester Grades
    \item Age at Enrollment
    \item Scholarship Holder
\end{enumerate}
\vspace{0.3cm}
\small{This transparency enables targeted interventions by educators.}
\end{column}
\begin{column}{0.5\textwidth}
\centering
% IMAGE 4: SHAP Summary Plot
% Source: 05_model_interpretability.ipynb - SHAP summary plot
% Save as images/shap_summary.png
\includegraphics[width=\textwidth]{images/shap_summary.png}
\\
\tiny{Figure 4: SHAP Feature Importance \\ Source: 05\_model\_interpretability.ipynb}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Explainability - SHAP Analysis (Local)}
\centering
% IMAGE 5: SHAP Force Plot (Local Explanation)
% Source: 05_model_interpretability.ipynb - Individual prediction explanation
% Save as images/shap_force_plot.png
\includegraphics[width=0.85\textwidth]{images/shap_force_plot.png}
\\
\tiny{Figure 5: SHAP Force Plot - Individual Student Prediction \\ Source: 05\_model\_interpretability.ipynb}

\vspace{0.3cm}
\small{Shows how each feature contributes to a specific student's dropout risk prediction.}
\end{frame}

\begin{frame}{Web Application - Streamlit Dashboard}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Features:}
\begin{itemize}
    \item Interactive input sidebar
    \item Real-time predictions
    \item Confidence scores
    \item Traffic light system:
    \begin{itemize}
        \item \textcolor{red}{Red}: Dropout
        \item \textcolor{orange}{Yellow}: Enrolled
        \item \textcolor{green}{Green}: Graduate
    \end{itemize}
\end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
\centering
% IMAGE 6: Streamlit App Screenshot
% Source: Screenshot from running: streamlit run app.py
% Save as images/streamlit_app.png
\includegraphics[width=\textwidth]{images/streamlit_app.png}
\\
\tiny{Figure 6: Streamlit Web Application Interface \\ Source: app.py}
\end{column}
\end{columns}
\end{frame}

% ===================================================== %
% 5. CONCLUSION
% ===================================================== %
\section{Conclusion and Future Work}

\begin{frame}{Conclusion}
\begin{itemize}
    \item Successfully developed an end-to-end ML solution for student dropout prediction
    \item Integrated diverse datasets to create a robust, generalizable model
    \item Achieved \textbf{$\sim$77\% accuracy} with Random Forest
    \item Implemented \textbf{SHAP} for model transparency
    \item Deployed a functional \textbf{Streamlit Web App} for real-world usage
\end{itemize}
\end{frame}

\begin{frame}{Future Work}
\begin{itemize}
    \item \textbf{Deep Learning:} Explore LSTM/RNN for temporal analysis of student grades over semesters
    \item \textbf{More Data:} Integrate real-time attendance data from university systems
    \item \textbf{Intervention System:} Automated email alerts to counselors for high-risk students
    \item \textbf{Expanded Features:} Include socio-economic indicators and extracurricular activities
\end{itemize}
\end{frame}

% ===================================================== %
% 6. REFERENCE
% ===================================================== %
\section{References}

\begin{frame}{References}
\begin{enumerate}
    \item Suleyman Alpaslan Sulak, Nigmet Koklu. (2024). Predicting Student Dropout Using Machine Learning Algorithms. \textit{Intelligent Methods in Engineering Sciences}.
    \item Carnevale, A. P., \& Desrochers, D. M. (2003). Standards for what? The economic roots of K-12 education standards. \textit{Educational Policy}.
    \item Vaarma, M. (2024). Predicting student dropouts with machine learning. \textit{Computers \& Education}.
\end{enumerate}
\end{frame}

% ---------------- Thank You ---------------------
\section*{}
\begin{frame}
\centering
\Huge Thank You \\
\vspace{1cm}
\normalsize
Questions?
\end{frame}

\end{document}
