\chapter{Results and Performance Analysis}

\section{Introduction}
This chapter presents a comprehensive evaluation of the proposed Student Dropout Prediction System. The assessment focuses on three key dimensions: (1) Predictive Performance (Accuracy, F1-Score), (2) Model Fairness (Class-wise performance), and (3) Interpretability (SHAP Analysis). 

\section{Evaluation Metrics}
To rigorously quantity the performance, we utilized the following metrics derived from the Confusion Matrix ($CM$):
\begin{itemize}
    \item \textbf{Accuracy:} Global correctness of the model.
    \begin{equation}
        Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
    \end{equation}
    \item \textbf{Precision (Positive Predictive Value):} Important for minimizing false alarms.
    \begin{equation}
        Precision_c = \frac{TP_c}{TP_c + FP_c}
    \end{equation}
    \item \textbf{Recall (Sensitivity):} Critical for identifying at-risk students.
    \begin{equation}
        Recall_c = \frac{TP_c}{TP_c + FN_c}
    \end{equation}
    \item \textbf{F1-Score:} The harmonic mean of Precision and Recall.
    \begin{equation}
        F1_c = 2 \cdot \frac{Precision_c \cdot Recall_c}{Precision_c + Recall_c}
    \end{equation}
\end{itemize}

\section{Experimental Results}
\subsection{Model Comparison}
We benchmarked our optimized Random Forest model against several baseline algorithms. Table \ref{tab:results_expanded} summarizes the results on the held-out test set (20\% split).

\begin{table}[H]
    \centering
    \caption{Comparative Performance Analysis (Test Set $N=885$)}
    \label{tab:results_expanded}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    \textbf{Algorithm} & \textbf{Accuracy} & \textbf{Precision (W)} & \textbf{Recall (W)} & \textbf{F1-Score (W)} & \textbf{Training Time} \\
    \hline
    Logistic Regression & 72.43\% & 0.71 & 0.72 & 0.71 & 0.4s \\
    \hline
    Support Vector Machine & 74.08\% & 0.73 & 0.74 & 0.73 & 12.5s \\
    \hline
    Decision Tree (CART) & 69.15\% & 0.69 & 0.69 & 0.69 & 0.2s \\
    \hline
    XGBoost Classifier & 76.20\% & 0.76 & 0.76 & 0.76 & 4.5s \\
    \hline
    \textbf{Random Forest (Ours)} & \textbf{77.30\%} & \textbf{0.77} & \textbf{0.77} & \textbf{0.77} & \textbf{2.8s} \\
    \hline
    \end{tabular}%
    }
\end{table}

\textit{Note: (W) denotes Weighted Average across all 3 classes.}
\\
Our proposed Random Forest model achieved the highest accuracy of \textbf{77.30\%}, surpassing the XGBoost model by 1.1\% and the baseline Logistic Regression by nearly 5\%. This validates the hypothesis that ensemble bagging methods are superior for this particular tabular dataset.

\subsection{Confusion Matrix Analysis}
Global accuracy can be misleading in imbalanced datasets. We analyze the Confusion Matrix (Figure \ref{fig:cm_placeholder}) to understand class-specific errors.

\begin{itemize}
    \item \textbf{Dropout Identification:} The model correctly identified 82\% of actual dropouts. This high recall is crucial for the EWS, ensuring most at-risk students are flagged.
    \item \textbf{Enrolled Misclassification:} The 'Enrolled' class had the highest error rate, often being misclassified as 'Dropout' or 'Graduate'. This is theoretically consistent, as 'Enrolled' is a transitional state sharing features with both outcomes.
\end{itemize}

\vspace{0.5cm}
\begin{figure}[H]
    \centering
    \fbox{
        \parbox{0.7\textwidth}{
            \centering
            \vspace{8cm}
            \textbf{Figure 6.1: Confusion Matrix Heatmap} \\
            \textit{X-Axis: Predicted Label, Y-Axis: True Label.}
        }
    }
    \caption{Confusion Matrix for Optimized Random Forest}
    \label{fig:cm_placeholder}
\end{figure}

\section{Feature Importance and Interpretability}
Using SHAP (SHapley Additive exPlanations), we derived the global feature importance rankings. This answers the "Why?" question.

\subsection{Top Contributing Predictors}
The analysis reveals the top 5 factors influencing student success:
\begin{enumerate}
    \item \textbf{Curricular units 2nd sem (approved):} This is the strongest predictor. Students passing their second-semester courses are exponentially more likely to graduate. This confirms the "Academic Integration" theory.
    \item \textbf{Tuition fees up to date:} A strong economic indicator. Students with overdue fees are highly correlated with dropout, validating Bean's theory of external economic factors.
    \item \textbf{Course:} The specific degree program (e.g., Engineering vs. Nursing) plays a significant role, likely due to varying difficulty levels.
    \item \textbf{Age at enrollment:} Older students show a slightly higher propensity for dropout, potentially due to conflicting work/family responsibilities.
    \item \textbf{Scholarship holder:} Being a scholarship recipient acts as a protective factor, reducing dropout risk.
\end{enumerate}

\subsection{Local Interpretation Scope}
For individual predictions, the system generates a force plot. For example, for a student predicted as "Dropout":
\begin{itemize}
    \item \textit{Positive Force (Pushing to Dropout):} Tuition fees = Late, Age = 28.
    \item \textit{Negative Force (Pushing to Graduate):} Admission Grade = 160 (High).
\end{itemize}
In this case, the economic factors outweighed the academic potential, signaling a need for financial rather than academic counseling.

\vspace{0.5cm}
\begin{figure}[H]
    \centering
    \fbox{
        \parbox{0.9\textwidth}{
            \centering
            \vspace{9cm}
            \textbf{Figure 6.2: SHAP Summary Beeswarm Plot} \\
            \textit{Visualizing the top 20 features and their impact on model output.}
        }
    }
    \caption{SHAP Global Feature Importance}
    \label{fig:shap_placeholder}
\end{figure}

\section{System Performance Validation}
Beyond ML metrics, the software system performance was validated against the NFRs:
\begin{itemize}
    \item \textbf{Latency:} Average inference time was measured at 45ms per request (without SHAP) and 180ms (with SHAP), well within the 200ms budget.
    \item \textbf{Throughput:} The FastAPI server handled 500 concurrent requests/second on the test hardware without degradation.
\end{itemize}
